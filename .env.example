OPENAI_API_KEY=your_api_key_here
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=your_endpoint_here
LANGSMITH_API_KEY=your_api_key_here
LANGSMITH_PROJECT=your_project_name_here

# ============================================================
# KLARO AGENT CONFIGURATION
# ============================================================

# Recursion Limit: Maximum number of agent iterations before forced termination
# Controls how many times the agent can loop through run_model -> call_tool cycles
# Higher values allow more thorough analysis but risk infinite loops
# Default: 50
# KLARO_RECURSION_LIMIT=50

# ============================================================
# TIMEOUT CONFIGURATION (Prevents Hanging/Stalling)
# ============================================================

# Execution Timeout: Maximum seconds for entire agent execution
# Prevents agent from hanging indefinitely on large projects or API issues
# If execution exceeds this limit, agent will terminate with timeout error
# Recommended: 600s (10 minutes) for most projects, increase for very large codebases
# Default: 600
# KLARO_EXECUTION_TIMEOUT=600

# LLM Timeout: Maximum seconds to wait for LLM API response
# Prevents hanging when OpenAI API is slow or unresponsive
# If LLM call exceeds this limit, request will fail and agent will retry or terminate
# Recommended: 120s (2 minutes) for most cases
# Default: 120
# KLARO_LLM_TIMEOUT=120

# Tool Timeout: Maximum seconds for individual tool execution
# Currently not implemented (placeholder for future tool-level timeouts)
# Would prevent hanging on file I/O, ChromaDB operations, or long-running analysis
# Default: 60
# KLARO_TOOL_TIMEOUT=60

# ============================================================
# DEBUG CONFIGURATION
# ============================================================

# Debug Mode: Enable verbose logging to diagnose stalling issues
# When enabled, prints detailed progress messages showing:
# - Which node is executing (run_model, call_tool)
# - Routing decisions (why agent chose next step)
# - Tool execution details
# - LLM response previews
# Set to 'true' to enable debug logging, 'false' to disable
# Default: false
# KLARO_DEBUG=false

# ============================================================
# MODEL SELECTION CONFIGURATION
# ============================================================

# Auto Model Selection: Enable automatic model selection based on project size
# When enabled, Klaro analyzes project size and selects optimal model:
# - Small projects (< 10K lines): gpt-4o-mini (fast, cost-effective)
# - Medium projects (10K-100K lines): gpt-4o (balanced)
# - Large projects (> 100K lines): gpt-4-turbo (maximum capability)
# Set to 'false' to use fixed KLARO_DEFAULT_MODEL instead
# Default: true
# KLARO_AUTO_MODEL_SELECTION=true

# Default Model: Fixed model to use when auto-selection is disabled
# Override this to use a specific OpenAI model for all projects
# Default: gpt-4o
# KLARO_DEFAULT_MODEL=gpt-4o

# Model Override for Small Projects
# Default: gpt-4o-mini
# KLARO_SMALL_MODEL=gpt-4o-mini

# Model Override for Medium Projects
# Default: gpt-4o
# KLARO_MEDIUM_MODEL=gpt-4o

# Model Override for Large Projects
# Default: gpt-4-turbo
# KLARO_LARGE_MODEL=gpt-4-turbo